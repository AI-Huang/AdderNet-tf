{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Date    : Jan-29-21 14:38\n",
    "# @Author  : Kan HUANG (kan.huang@connect.ust.hk)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appendix: Dimensions' order\n",
    "\n",
    "PyTorch is *channel_first*:\n",
    "\n",
    "```Python\n",
    "images = torch.randint(0, 256, size=(N, C, H, W), dtype=torch.float32)\n",
    "kernels = torch.rand(size=(N_filters, C, ksize, ksize))\n",
    "```\n",
    "\n",
    "For TensorFlow:\n",
    "\n",
    "```Python\n",
    "images = tf.random.uniform((N, H, W, C), 0, 255, dtype=tf.dtypes.float32)\n",
    "kernels = tf.random.uniform((N_filters, ksize, ksize, C), 0, 255, dtype=tf.dtypes.float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, h_x, w_x, C = 16, 32, 32, 3\n",
    "N_filters, ksize, ksize, C = 6, 5, 5, 3\n",
    "\n",
    "images = torch.randint(0, 256, size=(N, C, h_x, w_x), dtype=torch.float32)\n",
    "kernels = torch.rand(size=(N_filters, C, ksize, ksize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 6, 30, 30])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = torch.nn.Conv2d(3,6,3) # in_channels, out_channels, kernel_size\n",
    "conv2d(images).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: torch.Size([16, 3, 32, 32])\n",
      "W.shape: torch.Size([6, 3, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "W, X = kernels, images\n",
    "print(f\"X.shape: {X.shape}\")\n",
    "print(f\"W.shape: {W.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30\n"
     ]
    }
   ],
   "source": [
    "# padding = 1, \"same\" 模式\n",
    "padding = 1 # 0, 1\n",
    "stride = 1\n",
    "\n",
    "# d_filter==d_x, when groups=1\n",
    "n_filters, d_filter, h_filter, w_filter = W.size()\n",
    "n_x, d_x, h_x, w_x = X.size()\n",
    "\n",
    "h_out = (h_x - h_filter + 2 * padding) / stride + 1\n",
    "w_out = (w_x - w_filter + 2 * padding) / stride + 1\n",
    "h_out, w_out = int(h_out), int(w_out)\n",
    "\n",
    "print(h_out, w_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfold\n",
    "\n",
    "两种表达没有区别：\n",
    "\n",
    "```Python\n",
    "unfold X.view(1, -1, h_x, w_x).view(n_x, -1, h_out*w_out)\n",
    "```\n",
    "\n",
    "```Python\n",
    "unfold X\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 75, 900])\n"
     ]
    }
   ],
   "source": [
    "# X.view(1, -1, h_x, w_x) # 这一句的作用是合并所有样本\n",
    "X_col = torch.nn.functional.unfold(\n",
    "    X.view(1, -1, h_x, w_x), h_filter, padding=padding, stride=stride).view(n_x, -1, h_out*w_out)\n",
    "print(X_col.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 75, 900])\n"
     ]
    }
   ],
   "source": [
    "# [N, C*\\product k_size_i, L]\n",
    "X_col1 = torch.nn.functional.unfold(\n",
    "    X, h_filter, padding=padding, stride=stride)\n",
    "print(X_col1.shape)\n",
    "# 16 images\n",
    "# 75 3x5x5 pixel values to Conv2D/Adder\n",
    "# 900 areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = X_col == X_col1\n",
    "# print(False in r.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfold results\n",
    "\n",
    "X_col: Tensor with shape $(N, C\\times\\prod(kernel\\_size),L)$\n",
    "\n",
    "$(N, C\\times\\prod(kernel\\_size),L)$\n",
    "\n",
    "$(N, C\\times\\prod(kernel\\_size),h_out, w_out)$\n",
    "\n",
    "h0\n",
    "w0~wxxx\n",
    "\n",
    "h1\n",
    "w0~....\n",
    "\n",
    "\n",
    "C-style: R-majoy\n",
    "\n",
    "#### Explanations\n",
    "\n",
    "N: sample index, keeps the same.\n",
    "\n",
    "$C\\times\\prod(kernel\\_size)$: perception area's size for each Conv2D/Adder operation. For example:\n",
    "\n",
    "|  channel_0   | channel_1  | channel_2|\n",
    "|  ----  | ----  |----  |\n",
    "| pixel values | pixel values | pixel values  |\n",
    "\n",
    "\n",
    "\n",
    "L: Perception area index dim. L is total output size for one image sample, and one filter.\n",
    "\n",
    "Actually $L=h_{out}\\times w_{out}$\n",
    "\n",
    "#### Appendix: Conv2D layer in PyTorch\n",
    "Inputs:\n",
    "\n",
    "X:  $(N, C_{\\text{in}}, H, W)$\n",
    "\n",
    "W: $(N_{filters}, C_{\\text{in}}, k\\_size, k\\_size)$\n",
    "\n",
    "Outputs:\n",
    "\n",
    "out: $(N, N_{filters}, H_{out}, W_{out})$\n",
    "\n",
    "$H_{out}, W_{out}$ depend on $H, W$ and `padding` and `strides`.\n",
    "\n",
    "#### Unfold\n",
    "\n",
    "[https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html](https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 75, 900])\n",
      "torch.Size([6, 75])\n"
     ]
    }
   ],
   "source": [
    "W_col = W.view(n_filters, -1)\n",
    "print(X_col.size()) # N, op_dim, out_dim\n",
    "print(W_col.size()) # N_filter, op_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([75, 14400])\n"
     ]
    }
   ],
   "source": [
    "# permute 交换维度顺序，把 N 维放到了最后，\n",
    "# X_col: [C* \\product k_size_i, h_out*w_out, N]\n",
    "X_col = X_col.permute(1, 2, 0).contiguous().view(X_col.size(1), -1)\n",
    "# X_col: [C* \\product k_size_i, (h_out*w_out)* N]\n",
    "print(X_col.size()) # [C* \\product k_size_i, h_out*w_out*N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_col.size(): torch.Size([75, 14400])\n",
      "W_col.size(): torch.Size([6, 75])\n",
      "torch.Size([6, 14400])\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_col.size(): {X_col.size()}\")\n",
    "print(f\"W_col.size(): {W_col.size()}\")\n",
    "# broadcasting to a common shape (PyTorch's feature)\n",
    "output = -(W_col.unsqueeze(2)-X_col.unsqueeze(0)).abs().sum(1)\n",
    "print(output.shape) # sum of the results in this batch and on all the channels\n",
    "\n",
    "# 900 * 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape output back\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.view(n_filters, h_out, w_out, n_x) # 注意维度顺序\n",
    "output = output.permute(3, 0, 1, 2).contiguous() # 改变维度顺序 -> (n_x, n_filters, h_out, w_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 6, 30, 30])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([75, 14400])\n",
      "torch.Size([6, 75])\n"
     ]
    }
   ],
   "source": [
    "print(X_col.size()) # [C* \\product k_size_i, h_out*w_out*N]\n",
    "print(W_col.size()) # [n_filters, C* \\product k_size_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 75, 14400])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = X_col.unsqueeze(0)-W_col.unsqueeze(2)\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from addernet.adder_torch import Adder2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = Adder2D(3, 16, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = layer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('torch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "fd47d156357233a90b4b9e1ced76382831df603b84b4e14e206f425091718cf9"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
